# Inteligencia Artificial en el Antropoceno: 
## Hacia una tecnopolítica crítica en la guerra de mundos

### Esquema del ensayo

---

## I. INTRODUCCIÓN: LA MONSTRUOSIDAD AMBIVALENTE DE LA IA

**Punto de partida**: La inteligencia artificial no es ni una herramienta neutra ni un ente autónomo amenazante, sino una monstruosidad ambivalente que exige ser pensada desde la equivocidad política más que desde certezas técnicas o apocalipsis tecnofóbicos.

**Tesis central**: El pensamiento crítico sobre IA debe abandonar tanto el instrumentalismo ingenuo como el determinismo tecnológico, para comprender cómo la IA se inserta en una transformación multiescalar del mundo que articula mediaciones computacionales ubicuas, crisis ambiental antropogénica y reconfiguración radical de la política como guerra de religiones entre públicos antagónicos.

---

## II. LA IA EN EL ANTROPOCENO POLÍTICO

### 2.1 La doble ruptura constitutiva

**Argumento**: La IA emerge en el contexto de una doble ruptura que define el mundo contemporáneo:

- **Primera ruptura**: Ya no es posible circunscribir un mundo social/cultural con independencia de las mediaciones tecnológicas. La IA no es un añadido a lo social, sino constitutiva de nuevas formas de subjetivación, organización y conocimiento.

- **Segunda ruptura**: Ya no es posible definir el mundo exclusivamente desde la acción humana. Se destituye la excepcionalidad de lo humano. La IA participa de un entrelazamiento irreductible entre vida, inteligencia, tecnología y naturaleza.

**Consecuencia**: La IA debe pensarse en el marco del Antropoceno, no como respuesta técnica a la crisis ambiental, sino como parte del problema y la solución simultáneamente. Los sistemas de IA requieren infraestructuras materiales extractivas (minería de tierras raras, consumo energético masivo, granjas de servidores) que inscriben la computación en la geología política del planeta.

### 2.2 Inteligencia sintética vs. inteligencia artificial

**Crítica terminológica**: El término "inteligencia artificial" es inadecuado porque:
- Sugiere una separación entre inteligencia humana y no-humana
- Oculta el carácter sintético: combinación de cognición computacional y cognición humana
- Invisibiliza las infraestructuras materiales y cognitivas planetarias

**Propuesta**: Hablar de "inteligencia sintética" para enfatizar:
- La co-constitución de humanos y no-humanos en procesos cognitivos
- El carácter distribuido de la agencia
- La necesidad de pensar en escalas multiescalares (desde lo molecular hasta lo planetario)

### 2.3 El déficit político de los debates sobre IA

**Diagnóstico**: Los debates actuales sobre IA reproducen tres vacuidades teóricas:

1. **Extensión privativa**: Se extienden categorías humanas a la IA sin revisarlas (autonomía, decisión, responsabilidad), repitiendo el antropocentrismo que se pretende superar.

2. **Ontología relacional vacía**: Proliferación de conceptos de "entrelazamiento" o "redes" que no generan nuevas prácticas políticas concretas, solo identidades académicas.

3. **Neologismos identitarios**: Vocabularios que funcionan como signos de pertenencia (ética de la IA, IA responsable, IA justa) sin confrontar las estructuras de poder reales.

**Resultado**: Un teatro de exhaustos que amplían teorías de la acción mientras humanos y planeta están agotados.

---

## III. GUERRA DE RELIGIONES Y VECTORES DE LA INFORMACIÓN

### 3.1 La lengua política del presente

**Tesis**: La disputa contemporánea sobre IA no se da en el lenguaje de la lucha de clases ni del conflicto ideológico, sino en la forma de una guerra de religiones entre públicos antagónicos con creencias inconmensurables.

**Características de los públicos contemporáneos**:
- Comunidades virales que se conforman por intereses parciales
- Múltiples pertenencias superpuestas (no un "pueblo" unificado)
- Producción descentralizada de información que destituye la autoridad vertical
- Enojo y malestar como afecto político primario
- Potencia destituyente más que constituyente

**La IA en esta guerra**: La inteligencia artificial funciona como:
- Objeto de creencias inconmensurables (salvación vs. apocalipsis)
- Terreno de batalla por el control de vectores de información
- Modulador de la economía de la atención que estructura los públicos

### 3.2 El antagonismo vectorial

**Concepto clave**: La disputa no es por la información en sí (que es infinita), sino por los vectores que la transmiten, almacenan y procesan.

**Los vectores de la IA**:
- **Sustrato material**: Minería, cables, satélites, granjas de servidores, chips
- **Sustrato procesal**: Algoritmos, modelos de lenguaje, arquitecturas de redes neuronales
- **Control corporativo**: Concentración en pocas empresas que administran tanto hardware como software

**Antagonismo central**: Entre quienes controlan los vectores (tecnofeudalismo, nanofundios) y quienes producen información dentro de ellos sin controlar su captura y procesamiento.

**Economía de la atención**: La IA no solo procesa información, sino que captura atención. Los sistemas de recomendación, los LLMs, los feeds algorítmicos modulan hacia dónde miramos, qué creemos, cómo nos relacionamos.

### 3.3 La batalla cultural y la IA

**Desplazamiento estratégico**: La derecha radical comprendió que la batalla es cultural antes que económica. El "globalismo woke" es identificado como una catedral cuyo dogma es la construcción social de la realidad.

**La IA en esta batalla**:
- Herramienta de la "catedral": Moderación de contenidos, fact-checking algorítmico, políticas de uso aceptable
- Herramienta de la contraofensiva: Bots, deepfakes, amplificación de narrativas alternativas, plataformas sin moderación
- Objeto de sospecha: ¿Qué sesgos codifican los modelos? ¿A quién beneficia el control de la IA?

**Hipocresía crítica**: El pensamiento crítico enseñó la sospecha, la desnaturalización, la construcción social. La derecha radical aprendió mejor estas herramientas y las usa para desmontar la legitimidad científico-técnica de las élites progresistas.

---

## IV. TECNOPOLÍTICA DE LA IA: NI RESISTENCIA NI ACELERACIÓN

### 4.1 Las dos trampas políticas

**Primera trampa: Governance tecnocrática**
- Reducción del problema de la IA a administración: comités de ética, regulaciones, auditorías
- Despolitización mediante experticia técnica
- Reproducción del globalismo sin cambiar estructuras de poder
- "IA responsable" como marca corporativa sin transformación real

**Segunda trampa: Radicalidad sin barro**
- Críticas radicales que no producen prácticas políticas efectivas
- Llamados a la resistencia sin organización concreta
- Vocabularios que funcionan como identidades académicas
- Denuncias del extractivismo computacional sin alternativas viables

**Diagnóstico**: Estamos atrapados entre una governance administrativa que no cambia nada y una radicalidad terrestre que tampoco cambia nada.

### 4.2 Radicalidad efectiva: Una tecnopolítica para la IA

**Principio**: Ni resistir la IA (ilusión de detener lo que ya está) ni acelerarla ciegamente, sino disputar su diseño, control y orientación.

**Doble estrategia**:

1. **Asumirse en guerra**: Identificar los territorios de disputa y entrar en batalla
   - Lucha por el software libre y los modelos abiertos
   - Disputa por la infraestructura material (soberanía computacional)
   - Construcción de alternativas concretas (cooperativas de datos, IA comunitaria)

2. **Cambiar de terreno**: No discutir en los términos del enemigo
   - No hablar el lenguaje de la "ética de la IA" sino de geopolítica del cómputo
   - No centrarse solo en sesgos algorítmicos sino en economía política de los datos
   - No asumir la narrativa del progreso inevitable sino mostrar la pluralidad tecnológica

**Tareas concretas**:
- Restituir fuerzas públicas que disputen con corporaciones privadas
- Volver bienes comunes lo que ha sido apropiado (datos, modelos, infraestructura)
- Establecer la tecnodiversidad como principio: múltiples IAs, múltiples cosmotécnicas, múltiples futuros

### 4.3 Redefinir los territorios políticos

**Nueva topología política**: La política de la IA no pasa solo por el Estado o las corporaciones, sino por nuevos territorios:

- **Plataformas digitales**: Espacios donde se configura la vida social, el trabajo, la subjetividad
- **Configuración de algoritmos**: Decisiones de diseño que tienen efectos políticos masivos
- **Extracción de materiales**: Minería de litio, cobre, tierras raras para infraestructura computacional
- **Producción de datos**: Trabajo invisible de etiquetado, moderación, entrenamiento

**Pregunta política central**: ¿Quién diseña el entrelazamiento entre humanos, tecnología y naturaleza que constituye la IA?

---

## V. VOCABULARIO PARA UNA POLÍTICA DE LA IA

### 5.1 Abandonar categorías obsoletas

**Lo que ya no funciona**:
- IA como "herramienta" (instrumentalismo ingenuo)
- IA como "amenaza existencial" (determinismo tecnológico)
- IA como "neutral" (ilusión tecnocrática)
- "Humanidad" vs. "máquinas" (excepcionalismo humano)
- "Ética de la IA" como solución (postpolítica)

### 5.2 Conceptos para una tecnopolítica crítica

**Inteligencia sintética**: Combinación de cognición humana y computacional en infraestructuras cognitivas planetarias.

**Vectores de información**: Infraestructuras materiales y procesales que transmiten, almacenan y procesan información (no neutrales sino objeto de control y disputa).

**Economía de la atención**: La IA no procesa solo datos sino que captura y modula atención humana en mercados donde se vende a anunciantes.

**Antropoceno computacional**: La IA no es solo software sino geología (minería), energía (consumo eléctrico masivo) y residuos (obsolescencia acelerada de hardware).

**Guerra de religiones algorítmicas**: Públicos antagónicos con creencias inconmensurables disputando en plataformas cuya arquitectura modula el conflicto.

**Tecnodiversidad**: Pluralidad irreductible de formas técnicas con diferentes signos políticos (no hay una sola IA sino múltiples IAs posibles).

**Radicalidad efectiva**: Ni governance tecnocrática ni resistencia romántica, sino disputa concreta por el diseño, control y orientación de las tecnologías.

### 5.3 Preguntas políticas fundamentales

En lugar de preguntar "¿es buena o mala la IA?", preguntar:

- ¿Quién controla los vectores de información que constituyen la IA?
- ¿Qué infraestructuras materiales sostienen la computación y a qué costo ambiental?
- ¿Qué formas de trabajo invisible producen los datos que entrenan los modelos?
- ¿Cómo se pueden comunalizar los bienes apropiados por las corporaciones?
- ¿Qué públicos se están constituyendo en relación con la IA y qué creencias los movilizan?
- ¿Qué futuros deseables se pueden imaginar con/contra/más allá de la IA?

---

## VI. HACIA UNA AGENDA DE RADICALIDAD EFECTIVA

### 6.1 En el terreno del sustrato material

**Geopolítica de los minerales**:
- Visibilizar la cadena extractiva que sostiene la IA (litio, cobalto, cobre, tierras raras)
- Disputar los términos del extractivismo: no solo "transición energética verde" sino justicia territorial
- Conectar luchas anti-extractivistas con crítica de la infraestructura computacional

**Soberanía energética y computacional**:
- Cuestionar el consumo energético de la IA (granjas de servidores, entrenamiento de modelos)
- Imaginar computaciones alternativas: menos intensivas, más distribuidas, más eficientes
- Desarrollar infraestructuras regionales que no dependan de monopolios corporativos

### 6.2 En el terreno del sustrato procesal

**Software libre y modelos abiertos**:
- Recuperar la tradición del software libre para los modelos de IA
- Resistir la apropiación corporativa mediante patentes y secretos comerciales
- Construir comunidades de desarrollo abierto y colaborativo

**Inteligencia sintética comunitaria**:
- Desarrollar sistemas de IA que potencien capacidades colectivas específicas (no "inteligencia general")
- Experimentar con arquitecturas que no repliquen lógicas corporativas
- Imaginar interfaces que no sean antropomórficas ni extractivas de atención

### 6.3 En el terreno de la organización política

**Nuevas formas organizativas**:
- Aprovechar las mediaciones computacionales para coordinación distribuida (sin caer en horizontalismo ingenuo)
- Experimentar con democracia computacional (no governance tecnocrática sino participación efectiva)
- Construir comunidades que vehiculicen el malestar contemporáneo hacia transformación y no hacia la derecha radical

**Pedagogía tecnopolítica**:
- Alfabetización no solo técnica sino política sobre IA
- Comprensión de la economía política de los datos
- Imaginación de futuros alternativos (no distópicos ni utópicos sino deseables)

### 6.4 En el terreno de la imaginación

**Futuros plurales**:
- Resistir la narrativa única del "progreso inevitable" de la IA
- Mostrar que hay múltiples trayectorias tecnológicas posibles (tecnodiversidad)
- Imaginar IAs que no sean corporativas, extractivas, homogeneizantes

**Monstruosidad ambivalente**:
- No purificar la IA como solo buena o solo mala
- Habitar la equivocidad: la IA como problema y posibilidad simultáneamente
- Asumir que ya somos ese monstruo nacido en el Antropoceno y preguntarnos qué componemos con él

---

## VII. CONCLUSIÓN: EL PENSAMIENTO CRÍTICO DESPUÉS DE LA CRÍTICA

### Autoconciencia del límite

**El problema del pensamiento crítico**: Heredamos herramientas de sospecha, desnaturalización, deconstrucción. La derecha radical las aprendió mejor que nosotros y las usa para desmontar la legitimidad del conocimiento experto, la ciencia del clima, la regulación de la IA.

**La trampa de la catedral**: Si nos asumimos como custodios de la verdad crítica sobre la IA, reproducimos el gesto que la derecha denuncia: una élite bienpensante que dice la verdad desde la torre de marfil.

**Necesidad de desfiguración**: El pensamiento crítico sobre IA debe arriesgarse a no reconocerse en el espejo. Abandonar certezas, habitar la desorientación, generar equivocidad donde todo parece claro.

### La doble tarea

1. **Confrontar**: Entrar en la guerra con armas efectivas. Disputar vectores, infraestructuras, diseños. Construir alternativas concretas que no sean solo resistencia.

2. **Desactivar**: Cambiar el terreno de batalla. No discutir en términos del enemigo. No asumir la narrativa del progreso inevitable ni la del apocalipsis tecnológico.

### La pregunta política fundamental

No es "¿qué es la IA?" sino "¿qué queremos hacer con la IA?"

No es "¿es buena o mala?" sino "¿quién la controla, cómo la disputamos, qué mundos abre o cierra?"

No es "¿cómo regularla?" sino "¿cómo redistribuir el poder sobre su diseño, desarrollo y despliegue?"

### El horizonte

**No hay paz**: Estamos en una guerra de religiones algorítmicas entre públicos antagónicos. Esta guerra se libra en los estratos del territorio (minería, energía) y en los vectores de las plataformas (algoritmos, datos).

**Radicalidad efectiva**: Ni governance tecnocrática ni resistencia romántica. Disputar concretamente el entrelazamiento entre humanos, tecnología y naturaleza que constituye la IA.

**Futuros plurales**: La IA no tiene un destino único. Hay múltiples IAs posibles, múltiples futuros en disputa. La tarea política es abrir esos mundos posibles, hacer de la IA un campo de batalla política y no de consensos técnicos.

**Quizás, política**: Si logramos heredar tradiciones latinoamericanas de pensamiento radical sobre tecnología y naturaleza, si inventamos vocabularios a la altura de nuestro tiempo, si organizamos radicalidad efectiva que vehiculice el malestar contemporáneo, entonces, quizás, política.

---

## BIBLIOGRAFÍA CONCEPTUAL

**Conceptos de los textos fuente**:

De "La nueva guerra de religiones":
- Públicos antagónicos
- Guerra de religiones
- Economía de la atención
- Antagonismo vectorial
- Batalla cultural
- Exhaustos de la tierra

De "Manifiesto tecnopolítico":
- Inteligencia sintética
- Antropoceno irregular
- Tecnodiversidad
- Radicalidad efectiva
- Infraestructuras cognitivas planetarias
- Entrelazamiento irreductible

De "Antropoceno político":
- Monstruosidad ambivalente
- Déficit político
- Imperialismo cognitivo
- Triple vacuidad teórica
- Teatro de los exhaustos
- Radicalidad efectiva
- Doble estrategia

---

## NOTAS METODOLÓGICAS

Este ensayo busca:

1. **Evitar las tres vacuidades teóricas**: No hacer extensión privativa de conceptos humanos a la IA, no disolver todo en ontologías relacionales vacías, no proliferar neologismos identitarios.

2. **Superar el déficit político**: No quedarse en diagnóstico catastrófico sin respuestas concretas, no apelar a governance tecnocrática ni a resistencia romántica.

3. **Habitar la equivocidad**: No purificar la IA como solo amenaza o solo promesa, sino como monstruosidad ambivalente que exige pensamiento político complejo.

4. **Proponer radicalidad efectiva**: Prácticas concretas que disputen el diseño, control y orientación de la IA sin caer en voluntarismo ni en determinismo.

5. **Articular escalas**: Desde lo molecular (chips) hasta lo planetario (consumo energético), desde lo individual (atención) hasta lo colectivo (públicos), desde lo material (minería) hasta lo procesal (algoritmos).

6. **Heredar tradiciones**: Recuperar pensamiento latinoamericano sobre tecnología, naturaleza y política para no repetir marcos eurocéntricos.

7. **Imaginar futuros**: No distópicos ni utópicos sino deseables, plurales, disputables.
