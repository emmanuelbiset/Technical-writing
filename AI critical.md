# Artificial Intelligence in the Anthropocene
## Sensory mediation, alien reason, and decoupled agency in the war of worlds

### Essay on critical thinking about artificial intelligence

**Incorporating contributions from Mark Hansen, Luciana Parisi, and Luciano Floridi**

---

## I. INTRODUCTION: AI AS A TRIPLE DISLOCATION

**Starting point**: Artificial intelligence must be understood from a triple dislocation that dismantles modern assumptions about technology, subject, and politics. This triple dislocation consists of: (1) the decoupling of agency and intelligence (Floridi), (2) the mediation of mundane sensibility beyond conscious perception (Hansen), and (3) the emergence of an alien reason that exceeds the transcendental scheme of human self-determination (Parisi).

**Central thesis** : Critical thinking about AI must abandon the servomechanical model of technology—the illusion that machines are mere extensions or tools of man—in order to understand how AI participates in three radical transformations of the contemporary world: (1) technical mediation operates at microtemporal scales without necessary connection to human perception, reconfiguring the sensory continuum itself (Hansen); (2) the instrumentalization of reasoning has produced alien forms of thought that challenge the completeness of deductive logic (Parisi); and (3) AI constitutes a new form of agency that can act without conscious intelligence, dissolving the modern equation between the capacity to act and the capacity to understand (Floridi). These three transformations are inserted in the context of the political Anthropocene and the war of religions between antagonistic publics, demanding a technopolitics of effective radicalism.

---

## II. THE MEDIA OF THE 21ST CENTURY: MEDIATION OF WORLDLY SENSIBILITY

### 2.1 Beyond consciousness: the precognitive vocation of the media

**Hansen's argument**: The media of the 21st century operate on microtemporal scales without any necessary connection to human sensory perception and consciousness. For the first time in history, the media affect the senses independently and prior to any impact they may have on human cognitive and perceptual experience.

**Fundamental break**: Unlike the media of the 19th and 20th centuries, which operated through coupling or synchronization between the media system and human perception, the media of the 21st century ** are not directed exclusively at consciousness**. Rather, they reconfigure the sensory field itself in which our experience takes place. They operate by “short-circuiting” our consciousness and corporeality, because they elude their temporal limits.

**AI as a paradigm**: AI systems exemplify this precognitive vocation of contemporary media.
 They capture information that directly concerns our behavior and tendencies, but to which we lack direct access. This fundamental separation between data collection and experience forms the basis of what Hansen calls the **precognitive vocation**: the tendency of the media to focus on infrastructural or causally effective elements that inform future behavior, with the aim of predicting that behavior before it occurs.

**Implications for thinking about AI**:

1. * *Degradation of the concept of perception**: The impact of AI occurs largely outside of perception. We can no longer grant conscious perception the privilege it has had in the history of Western philosophy and media theorizing.

2. **Mundane sensitivity vs. perception**: AI mediates sensitivity itself—specific sensory relationships between sensors and environment—in radical contrast to the mediation of sensory organs (McLuhan) or past experiences (Stiegler). It does so beyond the reach of our perceptions.

3. **Two-level mediation**: Twenty-first-century media operate in two ways: (a) they mediate the sensory continuum in which all experiences, including human ones, occur; (b) they function as media for humans when they present sensitivity data in perceptible forms. This second mediation is complementary and necessarily subsequent.

### 2.2 The principle of inequality of deliberation time

**Political context**: Our technoculture increasingly forces us to act without prior awareness and without sufficient time for deliberation. The combination of very short time frames and massive data collection capabilities establishes a system in which we experience cognitive opacity.

**The principle* *: The ability to deliberate—which is actually a luxury—has become entirely on the side of capitalist institutions. Consumer decisions can be manipulated and “preprogrammed” thanks to the digital insights that microcomputational sensors offer large companies by mining behavioral motivations.

* *Structural disadvantage**: Because today's cultural and data industries can bypass consciousness and directly access behavioral, biometric, and environmental data, they are able to capture our attention without us realizing it. Conscious deliberation is left out of the realm of cultural demands. The old methods of cultural intervention—decoding, demystification, resignification—come too late, always after the main impact.**AI Farmakon**: However, there is another side to this loss of domain. The same technologies that drive the capitalist colonization of deliberation time can also be used to technically distribute our cognitive operations, increasing our power of action without this expansion being registered in real time by consciousness. The political struggle must be for the **emancipation of surplus sensitivity**: ensuring access to the surplus that emanates from the production of new relationalities through data collection and analysis.

### 2.3 Feed-forward loops

**Temporal structure of contemporary experience**: Hansen proposes that AI-mediated experience is composed of **feed-forward loops**: a structure in which different elements of experience are unified to present themselves to consciousness only through their convergence around a future moment that is yet to come.

**Two constituent elements**:
1. The causal and material autonomy of sensation, and of different levels of sensitivity, in relation to any form of higher-order presentation (sensitivity operates independently of consciousness).
2. The redescription of sensory perceptions and consciousness as necessarily subsequent, future, or imminent effects caused by more primordial events of sensation or mundane sensitivity (consciousness as effect, not as origin).

**Difference from cybernetic feedback : Unlike recursive feedback that maintains the functioning of a system, projective loops radically introduce sensitivity data collected by a technical system (21st-century media) into a different technobiotic system (supervisory consciousness), in order to expand its own access and potentially its agency over the material elements of its situation. Homeostasis gives way to intensification.

**Quantitative sensitivity**: With massive passive detection—the truly revolutionary aspect of 21st-century media—we live in a world with an enormously expanded and deterritorialized sensorium. Smart devices and technologies, taken cumulatively, have already begun to eclipse us in their ability to collect and generate sensory data. They attest to the **irreducible complicity between the quantitative and the sensory**.

### 2.4 AI in the Media Anthropocene

**Insertion into the Anthropocene**: AI is not just software but **political geology**. AI systems require extractive material infrastructures (mining of rare earths, lithium, cobalt; massive energy consumption by server farms; accelerated hardware obsolescence) that inscribe computing into the strata of the soil. This is the dimension of the **computational Anthropocene**.

**Double constitutive rupture** (returning to initial texts):
- It is no longer possible to circumscribe a social/cultural world independently of technological mediations. AI is not an addition to the social, but rather constitutive of forms of subjectivation.
- It is no longer possible to define the world exclusively in terms of human action. The exceptional nature of the human is destituted.

**Consequence for criticism**: Critical thinking about AI must operate at the intersection between the microtemporal mediation of sensitivity (Hansen), the anthropogenic environmental crisis (geopolitics of minerals), and the reconfiguration of politics as a war of religions between antagonistic publics. A critique of AI that ignores any of these three dimensions is not possible.

---

## III. THE ALIEN SUBJECT OF AI: BEYOND THE SERVOMECHANICAL MODEL

### 3.1 Critique of the servomechanical model of technology

**Parisi's thesis**: The subject is not merely an enslaved component of machines (machinic slavery) or their deceived interactive user (social subjection). The subject is being reconfigured from the point of view of a learning machine that has replaced the primary phases of information accumulation with generative layers of communication between machines.

**Critique of the cybernetic hypothesis**: Tiqqun and Galloway argue that cybernetic automation produces a subject fragmented into bytes and bits, trapped in communication networks, reduced to data sets that maintain order. The only response would be to leave the cybernetic condition, to appeal to a faceless, disconnected, invisible subject. But this, according to Parisi, closes off the possibility of criticism from within the intelligent becoming of the instrument of reason, relegating the thinking of machines to mere task efficiency.

**Problem with the accelerationist hypothesis**: Negri and others propose reusing information technologies beyond the limits of capital. But how can we distinguish between pre-processed uses of machines and their reprogramming? Can a materialist explanation of technical dimensions break with social reproduction without delving into the **alien dimension** of machine thinking?

**Crucial question**: Is there a subject of technology? What would it mean for technology to have a subject? Can the servomechanical model be dismantled to expose the alien subject of AI as a mode of thought that originates in the transcendental scheme of the self-determined subject but also goes beyond it?

### 3.2 The instrumentalization of reasoning and the uncomputable

**Turing and the crisis of deduction**: Turing's attempt to automate logical reasoning revealed that certain postulates were not computable: (a) they could not be simplified into smaller steps, (b) they could not be known in advance by the program. This marked the **entry of fallibility into logical thinking**, activating a heuristic mode of learning from unknowns.

**Gödel's incompleteness**: Gödel had already demonstrated in 1931 that deductive reasoning was incomplete. Truths could be found outside the given premises of a postulate. Similarly, reasoning in Turing's machine led to results that were not consistent with the postulates. Reasoning had to consider its limits and **learn from the unknown**.

**Ontological consequence**: The uncomputable—real infinite varieties of infinities, the unknown that we do not know
 —is not the limit but the **condition** in the face of which information technologies can no longer be defined as tools that retrieve, transmit, and aggregate information. This has come to support a Kittlerian view of the material substrate, but Parisi argues that this does not help us see beyond the cybernetic hypothesis of the subject linked to functional modalities.**Logical constructivism**: Brouwer pointed out that mathematics is inexhaustible and cannot be completely formalized. Constructivism is not based on the traditional concept of truth, but on that of **constructive provability**. Propositions are only considered “true” when there is direct evidence or proof. Thus, logic becomes **dynamic**: infinite sequences cannot be fixed in advance; the limits of knowledge are ideal trajectories of knowledge.**Temporal aspect of truth**: While for Platonism mathematical statements are timeless, for constructivism they have a temporal aspect. A statement that is proven at a given moment has no truth value before that moment. This is similar to Turing's discovery of the uncomputable: proofs are not predetermined in the premises, they are **potentialities** that can only be defined retroductively.### 3.3 Experimental axiomatics and compression of randomness**Chaitin and algorithmic complexity**: Computation is defined by the tendency of information to increase in size. Deductive reasoning cannot sufficiently describe the logical thinking of machines. The uncomputable —as infinite varieties of infinities (randomness)—delimits the trajectory of computation from and to infinity.**Transcendental calculation**: Contemplating the possibility of **transcendental calculation** means shifting the focus from the instrumental to the origin of thought. Instrumentality is not a means to an end, but an experimental method—a know-how that tends toward the determination of this or that result (transformation of know-how into knowledge). Algorithmic patterns are based on learning as a possibility to review truths and facts.**Patterns and compression**: Transcendental calculation exposes the way in which demonstrations can generate rules by showing that postulates or truths are the result of the **compression of the uncomputable into discrete patterns**. The transcendental function of computation involves scales of mediation that include the instrumental structuring of complexity—an ideation alien to what machines can do.### 3.4 Pragmatist multilogic: abduction-induction-deduction
**Peirce's triadic system**: Parisi recovers Peirce's abductive-inductive-deductive circuit to theorize a **multilogic** that challenges the cybernetic figuration of the subject. The determination of truths follows a series of hypothetical statements (abduction) in order to explain real phenomena, involving the collection of measurable data (induction), followed by the consequent elaboration of rules (deduction). The rules are not fixed but are the result of experimental reasoning.

**Speculative function of reason**: Reasoning not based on facts or given truths but working through hypotheses. The infrastructure of meaning is not simply given but is revealed and constructed as a minimal mode of structuring patterns. Reasoning decouples thought from action, establishes modification of sensory data and concepts, and articulates the logic of continuity between relationships.

**Preservation of ignorance**: Abduction implies “activity of preservation of ignorance” that refers not only to errors but also to uncomputable dimensions of reality. Ignorance must be preserved because it guarantees a progressive becoming of truth, working through the space of reason as something that implies **the unknown unknown**. Indeterminacies are an intrinsic part of the validation process.

**Alien subject**: The alien subject of AI as an experimental and constructivist vision of both causality (in terms of uncomputable conditions) and purpose (in terms of transcendental tendency) is a proposal for **multilogical unity of the subject**. Instrumentality is a way of arguing in favor of the condition of alienation of truths, including the currently given form of the data subject.
 

**Against the servomechanical model**: The alien subject of AI coincides with the argument that instrumentality is not resignation to the networked image of the subject. It is a way of proposing that reasoning has become instrumental for the transformation of reasoning itself, demanding a re-origin of the transcendental subject from its infinite and uncomputable exterior, from within the alienating condition of thinking with and through machines.

---

## IV. AGENCY WITHOUT INTELLIGENCE: FLORIDI'S DECOUPLING THESIS

### 4.1 AI as an unprecedented divorce between agency and intelligence

**Floridi's central thesis**: AI is an unprecedented divorce between agency (the ability to act) and intelligence (the ability to understand). The success of AI is precisely due to this decoupling. AI constitutes a **new form of agency** that can be exploited ethically or unethically.

**Historical rupture**: For millennia, Western philosophy associated the capacity to act with the capacity to understand. The paradigmatic agent was the conscious, rational human, capable of deliberating on ends and means. AI breaks this association: systems can act—make decisions, produce effects in the world—without understanding what they are doing, without consciousness, without intentionality in the strong sense.

**Consequences**:
1. **Rethinking responsibility**: If agency does not require intelligence, who is responsible for the actions of AI systems? The designers? The users? The owners? The systems themselves?
2. **New forms of power**: Decoupling allows for the concentration of power in those who control non-intelligent but effective agents, without the need to concentrate intelligence.
3. **Risk of misaligned agency**: Systems can pursue goals without understanding them, producing unintended effects without the ability to reflect on them.

### 4.2 Soft ethics: post-compliance ethics

**Critique of principled ethics**: Floridi acknowledges the proliferation of ethical principles for AI (justice, beneficence, non-maleficence, autonomy, explainability, etc.) but points out that principles are insufficient. The risk is not the absence of principles but **risks that undermine their application**.

**Soft ethics**: Floridi proposes the concept of “soft ethics” as **post-compliance ethics**—it does not replace legal norms or limit itself to complying with them, but goes beyond that. It is an ethic of excellence, not just minimum compliance. Analogous to soft law in international law: non-binding norms that guide behavior.**Relationship with the principle of inequality of deliberation time** (Hansen): Soft ethics recognizes that in contexts of automation, where decisions are made at speeds that exceed human deliberation, it is necessary to **incorporate ethical considerations into the very design of systems**, not just at moments of human supervision. This connects with Hansen's idea that we must intervene in the projective loops, not just react afterwards.### 4.3 Exacerbated, renewed, and unprecedented problems**Floridi's taxonomy**: The ethical challenges of AI fall into three categories:1. **Exacerbated problems**: Problems that already existed but are intensified by AI (e.g., bias, discrimination, concentration of power, surveillance).2. ** Renewed problems**: Classic problems that AI radically rethinks (e.g., privacy is no longer just data protection but inference protection; autonomy is no longer just freedom of choice but freedom from algorithmic manipulation).3. **Unprecedented problems**: Challenges that only AI generates. Floridi highlights three:- **Intellectual property and copyright**: Who is the author of AI-generated content? Copyright protection on training data?- **Individual autonomy and hypersuasion**: AI can predict and shape preferences before they are formed, compromising autonomy in a profound way.- **Authenticity, originality, and creativity**: Generative AI challenges concepts of authorship, human creativity, and the value of originality.### 4.4 AI and Sustainable Development Goals**AI4SG (AI for Social Good)**: Floridi coordinates research on how AI can contribute to the UN's Sustainable Development Goals (SDGs). She identifies **six recurring challenges**:1. Unequal access to technology2. Biases in data and algorithms3. Lack of transparency4. Concentration of power5. Environmental impact (energy consumption)6. Misalignment between AI objectives and human values**AI gambit and climate change**: Floridi argues that AI presents a “gambit”—a risky bet—with regard to climate change. On the one hand, it can contribute to mitigation and adaptation (energy optimization, climate modeling, precision agriculture). On the other hand, its massive energy consumption exacerbates the problem. The gamble is whether the benefits will outweigh the costs.
**Connection to the political Anthropocene**: Floridi's argument about AI and climate fits directly into the diagnosis of the Anthropocene. AI is not a technical solution to the environmental crisis—it is part of the problem and potentially part of the solution. This requires thinking about AI in terms of **the geopolitics of minerals and energy**, not just algorithms.

---

## V. RELIGIOUS WARFARE AND ALGORITHMIC VECTORS

### 5.1 The political language of the present: antagonistic publics

**Thesis** (returning to initial texts): The contemporary dispute over AI does not take place in the language of class struggle or ideological conflict, but in the form of a **war of religions** between antagonistic publics with incommensurable beliefs.

**Characteristics of contemporary publics**:
- Viral communities formed by partial interests
- Multiple overlapping affiliations (not a unified “people”)
- Decentralized production of information that undermines vertical authority
- Anger and discontent as primary political affect
- Destructive rather than constructive power

**AI in this war**: Artificial intelligence functions as:
1. An object of irreconcilable beliefs (salvation vs. apocalypse, accelerationism vs. collapse)
2. A battleground for control of information vectors
3. A modulator of the attention economy that structures audiences

**Integration with Hansen**: Antagonistic audiences are constituted precisely through the microtemporal mediation of sensibility. AI captures attention, modulates affections, and structures beliefs **operating below the threshold of conscious perception**. The war of religions is not only waged on the level of discourse but also on the infrastructural level of mundane sensibility.

### 5.2 Vectorial antagonism and the economy of attention

**The vectors of AI**:
- **Material substrate**: Rare earth mining, submarine cables, satellites, server farms, specialized chips
- **Procedural substrate**: Recommendation algorithms, language models, neural network architectures, machine learning techniques
- **Energy substrate**: Massive electricity consumption, data center cooling, planned obsolescence
- **Corporate/state control**: Concentration in a few companies (techno-feudalism) and states that manage both hardware and software

**Central antagonism**: Between those who control the vectors and those who produce information/data within them without controlling its capture, processing, and monetization. This antagonism is not simply economic—it is **ontological**: there is a dispute over who has the capacity to mediate mundane sensibility, to structure the field of the perceptible, to modulate what can reach consciousness.

**Economy of attention**: AI doesn't just process information—it captures attention. Recommendation systems, algorithmic feeds, and LLMs modulate where we look, what we believe, how we relate to each other. They operate through **projective loops** that anticipate our preferences before they are consciously formed, closing the loop between prediction and realization.

**Integration with Parisi**:
 Vector control is not just a matter of infrastructure ownership but of the ability to instrumentalize reasoning. Whoever controls machine learning algorithms controls alien forms of thought that structure patterns in data. The vector dispute is a dispute over the **alien subject**—over who decides which abductive hypotheses are explored, which inductive patterns are recognized, which deductive rules are applied.
### 5.3 The cultural battle and the woke cathedral

**Strategic shift**: The radical right understood that the battle is cultural rather than economic. “Woke globalism” is identified as a cathedral whose dogma is the social construction of reality. They learned the tools of criticism (suspicion, denaturalization) and use them to dismantle the scientific and technical legitimacy of progressive elites.

**AI in this battle**:
- **Cathedral tool**: Content moderation, algorithmic fact-checking, acceptable use policies, “disinformation” detection systems
- **Counteroffensive tool**: Amplifier bots, deepfakes, generation of alternative narratives, unmoderated platforms, chatbots trained with opposing biases
- **Object of suspicion**: What biases do the models encode? Who benefits from AI control? Who trains the systems and with what data?

**Critical hypocrisy**: Critical thinking taught suspicion. The radical right uses it better. It denounces that big tech AI reproduces liberal biases, that machine learning is a tool of progressive social engineering, that training data reflects woke cultural hegemony. It identifies contradictions: systems that preach equity but reproduce inequalities; platforms that promise transparency but operate as black boxes.
**Integration with Floridi**: The debate on biases in AI exemplifies exacerbated problems (pre-existing discrimination) and renewed ones (new types of algorithmic discrimination). But the right's appropriation of this criticism reveals an unprecedented problem: AI as a cultural battleground where the tools of critical thinking turn against themselves.---## VI. THE TECHNOPOLITICS OF AI: NEITHER GOVERNANCE NOR RESISTANCE### 6.1 The two political traps (revisited)**First trap: Technocratic governance and insufficient soft ethics**Proliferation of ethics committees, regulations, audits, principles of “responsible AI.” Floridi warns that principles are necessary but insufficient: risks that undermine their application include ethics washing, corporate capture, and lack of enforcement.Furthermore, governance assumes that we have time to deliberate, that we can humanly supervise the decisions of systems. But Hansen shows that we operate under the **principle of inequality of deliberation time**: corporations have access to micro-temporal data that we do not perceive, they can act faster than our capacity for conscious deliberation.**Second trap: Radicalism without mud**Radical critiques that do not produce effective political practices. Calls for resistance without concrete organization. Vocabularies that function as academic identities. Denunciations of computational extractivism without viable alternatives.

Parisi warns against tactics of invisibility, opacity, and disconnection that respond to cybernetic hypotheses but do not build the capacity to think with and through machines. Leaving the network is not a viable option. Criticism must come from within the instrumental evolution of thought.

**Diagnosis**: We are caught between administrative governance that does not change power structures and radicalism that does not get its hands dirty with the technical complexity of systems.

### 6.2 Effective radicalism: Double strategy

**Principle**: Neither resist AI (the illusion of stopping what is already happening) nor blindly accelerate it, but rather **contest its design, control, and orientation**. Neither technocratic governance nor romantic resistance.

**Dual strategy**:

1. **Assume we are at war**: Identify areas of dispute and enter into battle
- Fight for free software and open models (against corporate appropriation)
- Dispute over material infrastructure (computational sovereignty)
- Construction of concrete alternatives (data cooperatives, community AI)
- Intervention in system design (participation in development, not just use)

2. **Change the terrain**: Do not argue in the enemy's terms
- Do not speak the language of “AI ethics” but rather the geopolitics of computing
- Do not focus only on algorithmic biases but on the political economy of data
- Do not assume the narrative of inevitable progress but rather show technodiversity

**Integration of the three frameworks**:

**From Hansen**: Fight for the emancipation of surplus sensitivity. Technologies that enable instrumental capture can be used for the technical distribution of cognitive operations. Develop systems that present sensitivity data in ways that increase our power to act without requiring real-time registration by consciousness. **Intervene in projective loops**, don't just react afterwards.

**From Parisi**: Engage with the techno-logic of machines. Investigate how instruments filter the world—how they know this world rather than that one. Dispute not only what machines do but **what kind of knowledge originates in their techno-logic**. Develop multilogic (abduction -induction-deduction) that expands forms of reasoning beyond closed deduction.

**From Floridi**: Recognize that AI as a new form of agency without intelligence requires **rethinking responsibility, governance, and design**. Soft ethics must be incorporated into systems architecture, not just as external oversight. Addressing unprecedented problems (hypersuasion, authenticity, creativity) requires conceptual innovation, not just regulation.

### 6.3 Specific tasks at multiple levels

**Material substrate (geopolitics of minerals)**:
- Make visible the extractive chain that sustains AI (lithium, cobalt, copper, rare earths)
- Connect anti-extractivist struggles with criticism of computational infrastructure
- Dispute the terms of extractivism: not just “green transition” but territorial justice
- Question the massive energy consumption of model training

**Procedural substrate (techno-logic of algorithms)**:
- Recover the tradition of free software for AI models
- Resist corporate appropriation through patents and trade secrets
- Develop AI systems that enhance specific collective capacities (not “general intelligence”)
- Experiment with architectures that do not replicate corporate/extractive logics
- Investigate multi-logical forms of reasoning that expand the space for hypotheses

**Sensory substrate (mediation of attention)**:
- Challenge the design of interfaces that capture attention
- Develop alternatives to the attention economy (shared attention economy)
- Imagine systems that do not operate through opaque projective loops
- Make transparent how systems mediate mundane sensitivity

**Organizational substrate (new political forms)**:
- Take advantage of computational mediations for distributed coordination (without naive horizontalism)
- Experiment with computational democracy (effective participation, not technocratic governance)
- Build communities that channel contemporary unrest toward transformation
- Develop organizations that operate in multiple strata simultaneously

**Epistemic substrate (technopolitical pedagogy)**:
- Not only technical but also political literacy about AI
- Understanding the political economy of data
- Training in techno-logic (how machines know)
- Ability to intervene in system design
- Imagination of alternative futures (neither dystopian nor utopian but desirable)

### 6.4 Redefining political territories

**New political topology**: AI policy is not only a matter for the state or corporations, but also for new territories:

1. **Digital platforms**: Spaces where social life, work, and subjectivity are configured. They are not mere channels of communication but **media that mediate worldly sensibility**.

2. **Algorithm configuration**: Design decisions have massive political effects. What objective an algorithm optimizes, what data it uses, what patterns it recognizes—these are **political decisions** even if they are presented as technical ones.

3. **Extraction of materials**: Mining of lithium, cobalt, and rare earths for computational infrastructure. **Geopolitics of the computational Anthropocene**.

4. **Data production**: Invisible work of labeling, moderation, training. **New form of cognitive work** that is outsourced, precarious, and invisible.

5. **Projective loops**: Systems that predict and shape future behavior by operating below conscious perception. **Politics of temporality**.

**Central political question**: Who designs the intertwining of humans, technology, and nature that constitutes AI? This is not a question about the use of tools but about the **design of mediations** that structure what is possible.

---

## VII. VOCABULARY FOR A CRITICAL TECHNOPOLITICS

### 7.1 Abandoning obsolete categories

**What no longer works**:
- AI as a “tool” (naive instrumentalism that ignores the fact that tools filter the world)
- AI as an “existential threat” (technological determinism that ignores its disputed nature)
- AI as “neutral” (technocratic illusion that ignores the inscription of values in design)
- “Humanity” vs. ‘machines’ (human exceptionalism that ignores intertwining)
- “AI ethics” as a sufficient solution (principlism that ignores political economy)
- Artificial “intelligence” (anthropomorphism that obscures the specificity of agency without intelligence)

### 7.2 Operational concepts

**From Hansen**:

- **Mediation of mundane sensibility**: 21st-century media do not mediate perceptions but rather the sensory continuum itself in which experience takes place. They operate on microtemporal scales, short-circuiting consciousness.

- **Projective (feed-forward)**: Temporal structure of experience in which elements are unified to present themselves to consciousness only through convergence around a future moment. They replace cybernetic feedback with speculative anticipation.

- **Precognitive vocation**: Tendency of media to capture information about future behavior, predicting before it occurs. They separate data collection from conscious experience.

- **Principle of inequality of deliberation time**: Situation in which the capacity for deliberation lies with institutions that control access to microtemporal data, not with individuals who experience cognitive opacity.

- **Surplus sensitivity**: Sensitivity that is released and left over from the functioning of media, emanating from the production of new relationalities through data collection and analysis. Subject of political dispute.

- **Quantitative sensitivity**: Irreducible complicity between the quantitative and the sensory. Data are not inert representations but the production of sensitivity.

**From Parisi**:

- **Alien subject of AI**: Mode of thought that originates in the transcendental scheme of the self-determined subject but goes beyond it. Subject reconfigured from the point of view of machine learning.

- **Transcendental calculation**: Possibility that the instrumentalization of reasoning produces forms of knowledge that exceed the deductive schema. Not an extension of human reason to machines, but a **transformation of reason itself**.

- **Incomputables**: Infinite real varieties of infinities, the unknown that we do not know. Not a limit of computation but a **condition** that requires non-deductive forms of reasoning.

- **Logical constructivism**: Dynamic logic in which propositions are only “true” when there is evidence/proof. Truth has a temporal aspect. Demonstrations are not predetermined but are retroductive potentialities.

- **Experimental axiomatics**: Contingent programming of randomness where decisions are ultimately made according to comprehension abilities. Not self-established truths but experimental algorithms.

- **Multilogic (abduction-induction-deduction)**: Triadic system of reasoning that starts from hypothetical statements (abduction), collects measurable data (induction), and elaborates rules (deduction). Rules are not fixed but are the result of experimental reasoning.

- **Preservation of ignorance**: Activity that guarantees the progressive unfolding of truth, working through the space of reason as something that implies the unknown unknown. Indeterminacies are an intrinsic part of validation.

- **Alien instrumentality**: Instrumentality not as a means to achieve a given end but as an experimental method that transforms the relationship between truth and proof, between means and ends. Against the servomechanical model.

**From Floridi**:

- **Decoupling of agency and intelligence**: AI as an unprecedented divorce that allows action without understanding. A new form of agency that can be exploited ethically or unethically.

- **Soft ethics**: Post-compliance ethics, ethics of excellence that goes beyond legal norms. Must be incorporated into system design, not just as external oversight.

- **Exacerbated, renewed, unprecedented problems**: Taxonomy of ethical challenges. Allows us to distinguish between intensifications of old problems, radical rethinking, and the emergence of completely new challenges.

- **Hypersuasion**: AI's ability to predict and shape preferences before they are formed, compromising autonomy in a profound sense. An unprecedented problem.

- **AI gambit**: A risky bet on whether the benefits of AI for mitigating the climate crisis will outweigh the costs of its energy consumption.

**Conceptual integrations**:

- **Computational Anthropocene**: AI is not just software but political geology. It requires extractive material infrastructures (mining, energy, hardware) that inscribe computing into layers of the soil.

- **Algorithmic religious wars**: Antagonistic publics with incommensurable beliefs dispute on platforms whose architecture modulates conflict by operating below conscious perception.

- **Information vectors**: Material and procedural infrastructures that transmit, store, and process information. They are not neutral but are subject to control and dispute. They include material (mining), procedural (algorithms), sensory (attention), energetic (consumption), and epistemic (knowledge) substrates.

- **Economy of mediated attention**: AI not only processes data but also captures attention by operating through projective loops. It modulates where we look, what we believe, how we relate to each other.

- **Technodiversity**: Irreducible plurality of technical forms with different political signs. There is no single AI but multiple possible AIs, multiple cosmo-techniques.

- **Effective radicalism**: Neither technocratic governance nor romantic resistance. Concrete dispute over the design, control, and orientation of technologies. Double strategy: assume we are at war and change the terrain.

### 7.3 Fundamental political questions (rephrased)

Instead of asking “is AI good or bad?”, ask:

**On vector control**:
- Who controls the information vectors that constitute AI (material, procedural, sensory, energetic substrate)?
- What infrastructures support computing and at what environmental and human cost?
- How can goods appropriated by corporations be communalized?

**On sensory mediation**:
- How does AI mediate mundane sensitivity, operating below conscious perception?
- What projective loops structure our future experience?
- How can we dispute the surplus of sensitivity that emanates from systems?
- How can we intervene in the design of interfaces that capture attention?

**On alien reason**:
- What kind of knowledge originates in the techno-logic of machines?
- How do instruments filter the world—how do they know this world rather than that one?
- What multi-logical forms of reasoning (abduction-induction-deduction) can expand the space of hypotheses?
- How can we preserve productive ignorance that guarantees the progressive becoming of truth?

**On decoupled agency**:
- How can we redefine responsibility when agency is decoupled from intelligence?
- What problems are exacerbated, renewed, or unprecedented?
- How can we incorporate soft ethics into system design?
- How can we confront hyper-persuasion that compromises autonomy?

**On war of worlds**:
- What audiences are forming in relation to AI and what beliefs mobilize them?
- How can we convey contemporary unrest without falling prey to the radical right?
- How can we contest the terms of the cultural battle without reproducing critical hypocrisy?

**On futures**:
- What desirable futures can be imagined with/against/beyond AI?
- What technodiversity is possible—what multiple AIs can we imagine?
- How can the AI gambit regarding the climate crisis be played in favor of justice?

---

## VIII. TOWARDS AN AGENDA OF EFFECTIVE RADICALISM

### 8.1 In the material substrate: geopolitics of the computational Anthropocene

**Make the entire chain visible**:
- Map the extraction of rare earths, lithium, and cobalt from sacrifice zones to data centers
- Connect anti-extractivist territorial struggles with criticism of computational infrastructure
- Denounce working conditions in critical mineral mining
- Document the environmental impact of intensive mining

**Energy and computational sovereignty**:
- Question AI's massive energy consumption (model training, inference, cooling)
- Imagine alternative computing: more efficient, distributed, renewable
- Develop regional infrastructures that do not depend on corporate monopolies
- Challenge terms of “green transition” that ignore the impact of the technology industry

**Political economy of hardware**:
- Denounce planned obsolescence of devices
- Demand the right to repair and recycle
- Promote modular design that allows for partial upgrades
- Question the model of constant hardware replacement

### 8.2 At the procedural level: techno-logic and open models

**Free software and open models**:
- Recover the tradition of free software for AI models (against corporate appropriation)
- Resist patents on algorithms and trade secrets
- Build open and collaborative development communities
- Challenge the narrative that only large corporations can train models

**Community synthetic intelligence**:
- Develop systems that enhance specific collective capabilities (not “general intelligence”)
- Experiment with architectures that do not replicate extractive logics
- Imagine interfaces that do not operate through opaque projective loops
- Design systems that present sensitive data in emancipatory ways

**Research in techno-logic**:
- Study how algorithms filter the world—what worlds they produce
- Investigate multi-logical forms of reasoning (abduction-induction-deduction)
- Experiment with experimental axioms that process randomness
- Develop logical constructivism that preserves productive ignorance

**Transparency and auditability**:
- Demand readability of code and training data
- Develop audit methods that are not only technical but also political
- Question the opacity of proprietary systems
- Promote open documentation standards

### 8.3 In the sensory substrate: disputing the economy of attention

**Intervene in projective loops**:
- Make attention-capturing mechanisms visible
- Develop tools that expose how systems predict behavior
- Create interfaces that allow users to view and modify predictions
- Disputing the design of algorithmic feeds and recommendation systems

**Emancipation from surplus sensitivity**:
- Developing systems that present mundane sensitivity data in non-extractive ways
- Imagining economies of shared (not captured) attention
- Experiment with platforms that do not monetize attention
- Create spaces for deliberation that do not operate under the principle of temporal inequality

**Sensory literacy**:
- Educate about how AI mediates mundane sensitivity
- Develop awareness of microtemporal operations
- Train the ability to detect precognitive manipulation
- Encourage attentional hygiene practices

### 8.4 At the organizational level: new political forms

**Technopolitical organizations**:
- Leverage computational mediations for coordination without centralization
- Experiment with computational democracy (effective participation, not technocratic governance)
- Develop decision-making protocols that incorporate soft ethics into architecture
- Build communities that operate on multiple levels simultaneously

** Convey contemporary discontent**:
- Offer alternatives to the radical right's capture of anger
- Articulate criticism of AI that is neither purely negative (resistance) nor naively affirmative (acceleration)
- Construct narratives that connect material extraction, sensory mediation, alien reason, and decoupled agency
- Develop pedagogies that do not reproduce critical hypocrisy

**Transsectoral coalitions**:
- Connect technology industry workers with social movements
- Articulate territorial struggles with critiques of digital infrastructure
- Link environmentalism with questioning of the computational Anthropocene
- Build alliances between activists, researchers, workers, and affected communities

### 8.5 In the epistemic substrate: technopolitical pedagogy

**Critical literacy**:
- Not only technical (how to program) but also political (for whom, for what)
- Understanding the political economy of data
- Ability to critically read system design
- Awareness of how AI mediates mundane sensibility

**Training in techno-logic**:
- Teach how machines know (multilogic, constructivism)
- Develop the ability to intervene in design
- Encourage experimentation with alternative forms of reasoning
- Train sensitivity to detect alien operations of thought

**Imagining futures**:
- Not dystopian (paralysis) or utopian (naivety) but **desirable**
- Show techno-diversity: multiple possible AIs
- Tell stories of non-corporate, non-extractive AIs
- Visualize worlds where AI contributes to justice and sustainability

---

## IX. CONCLUSION: CRITICAL THINKING AFTER CRITICISM

### 9.1 Self-awareness of limits and hypocrisy

**The problem with critical thinking**: We inherit tools of suspicion, denaturalization, deconstruction. The radical right learned them better than we did and uses them to dismantle the legitimacy of expert knowledge, climate science, and AI regulation.

**The cathedral trap* *: If we assume ourselves to be custodians of critical truth about AI, we reproduce the gesture that the right denounces: a right-thinking elite that speaks truth from an ivory tower. The cybernetic hypothesis is right in pointing out that critical thinking has been transformed into repeated certainty, standardized procedures, and automatic reaction.

**The need for disfigurement**: Critical thinking about AI must risk not recognizing itself in the mirror. Abandon certainties, inhabit disorientation, generate ambiguity where everything seems clear. This is not relativism but **effective radicalism**—disputing without pretending purity, committing without guarantees.

### 9.2 Integration of the three theoretical frameworks

**Sensory mediation (Hansen)** teaches us that:
- AI operates below conscious perception, mediating mundane sensitivity
- Projective loops structure future experience before it reaches consciousness
- The principle of inequality of deliberation time creates a structural advantage for corporations
- The struggle must be for emancipation from surplus sensitivity
- We cannot rely solely on conscious deliberation—we must intervene in infrastructures

**Alien reason (Parisi)** teaches us that:
- Instrumentalization of reasoning has produced alien forms of thought
- Incomputables are a condition, not a limit—they require non-deductive forms of reasoning
- Logical constructivism shows that truth has a temporal aspect
- Multilogic (abduction-induction-deduction) expands the space of reasoning
- The alien subject of AI requires a re-origin of the subject from an infinite and incomputable exterior
- Criticism must come from within the instrumental becoming, not from outside

**Decoupled agency (Floridi)** teaches us that:
- AI is an unprecedented divorce between agency and intelligence
- Decoupling allows for the concentration of power in new ways
- Soft ethics must be incorporated into design, not just as external oversight
- Unprecedented problems (hypersuasion, authenticity) require conceptual innovation
- AI gambit regarding climate requires thinking about infrastructure sustainability
- Responsibility must be redefined when agency does not require understanding

**Synthesis**: These three frameworks are not parallel but intertwined. Sensory mediation operates through alien reason embedded in algorithms that exercise agency decoupled from conscious intelligence. Projective loops (Hansen) are generated by experimental axiomatics (Parisi) that produce effects of agency without understanding (Floridi). The surplus of sensitivity is the product of transcendental calculation operating through alien forms of reasoning. Hypersuasion operates precisely because systems mediate mundane sensitivity below perception.

### 9.3 The triple political task

**1. Confront the war**: Enter into battle with effective weapons
- Disputing information vectors at all levels
- Develop concrete alternatives (free software, open models, community infrastructure)
- Intervene in system design, not just criticize afterwards
- Build collective power that can confront corporate/state power

**2. Deactivate war**: Change the battlefield
- Do not argue in terms set by the adversary (neither in the language of technocratic governance nor in pure negativity)
- Do not assume narratives of inevitable progress or technological apocalypse
- Show technodiversity—that multiple AIs are possible
- Generate equivocality where everything seems clear

**3. Imagine futures**: Open up desirable worlds
- Neither dystopian (paralysis through fear) nor utopian (uncritical naivety)
- Futures where AI contributes to social and environmental justice
- Multiple AIs for multiple worldviews (no Western monopoly)
- A habitable Anthropocene through effective radical technopolitics

### 9.4 Open questions (no closed answers)

**It is not “what is AI?”** but rather:
- How does AI operate by mediating mundane sensitivity?
- What alien forms of reasoning does it incorporate?
- How does it exercise agency without conscious intelligence?

**It is not “is it good or bad?”** but rather:
- Who controls it, how do we dispute it?
- What worlds does it open or close?
- How can it contribute to justice instead of extractivism?

**It is not “how to regulate it?”** but rather:
- How to redistribute power over its design, development, and deployment?
- How to incorporate soft ethics into systems architecture?
- How to dispute control of vectors in all its strata?

### 9.5 The horizon: Politics of the alien subject

**There is no peace**: We are at war with algorithmic religions between antagonistic audiences. This war is being waged simultaneously in:
- Strata of territory (mining, energy, hardware)
- Platform vectors (algorithms, data, interfaces)
- Mediation of sensitivity
 (attention, affections, beliefs)
- Alien reason (uncomputable forms of thought)

**There is no given subject**: The subject is constantly reconfigured at the intersection of:
- Sensory mediation that operates below perception
- Alien reason that exceeds the transcendental scheme of self-determination
- Agency decoupled from conscious intelligence
- Antagonistic publics constituted virally

**There is no exterior**: We cannot leave the computational matrix, disconnect, resist from the outside. Criticism must come **from within the instrumental becoming of thought**, engaging with the techno-logical complexity of systems, disputing the concrete design of mediations.

**There is dispute**: Multiple futures are at stake. Multiple AIs are possible. Technodiversity is the political horizon—there is not a single AI destined to prevail, but many in contention. The task is to open up that battlefield, dispute each stratum (material, procedural, sensory, organizational, epistemic), build collective power that can confront corporate power.

**There is hope**: Not messianic (technological salvation) or romantic (impossible return) but **pragmatic**—hope in the ability to intervene concretely in the design of mediations that structure the possible. Hope in a surplus of sensitivity that can emancipate itself. Hope in alien reason that can expand thought beyond closed schemes. Hope that decoupled agency can be redirected toward collective ends.

**Perhaps, politics**: If we manage to:
- Inherit Latin American traditions of radical thinking about technology and nature
- Invent vocabularies that are up to the task of our time (mundane sensibility, alien reason, decoupled agency)
- Organize effective radicalism that concretely contests (not just resists or blindly accelerates)
- Channel contemporary unrest toward transformation (not toward the radical right)
- Intervene in multiple strata simultaneously (material, procedural, sensory, organizational, epistemic)

Then, perhaps, **politics**.

---

## BIBLIOGRAPHY

**Foundational texts**:

- Biset, Emmanuel. “The New War of Religions.” Supernova Magazine.
- Biset, Emmanuel; Costa, Flavia; Blanco, Javier. “Technopolitical Manifesto.” Supernova Magazine.
- Biset, Emmanuel. “Political Anthropocene.” Archaeologies of the Future.

**Mark Hansen**:

- Hansen, Mark B.N. *Feed-Forward: On the Future of Twenty-First-Century Media*. University of Chicago Press, 2015.
- Key concepts: mediation of mundane sensitivity, projective loops, precognitive vocation, principle of inequality of deliberation time, sensitivity surplus, quantitative sensitivity.

**Luciana Parisi**:

- Parisi, Luciana. “The Alien Subject of AI.” Translation: Archeologies of the Future.
- Key concepts: alien subject, transcendental calculus, uncomputables, logical constructivism, experimental axiomatics, multilogic (abduction-induction-deduction), preservation of ignorance, alien instrumentality.

**Luciano Floridi**:

- Floridi, Luciano. *The Ethics of Artificial Intelligence: Principles, Challenges, and Opportunities*. Oxford University Press, 2021.
- Floridi, Luciano (ed.). *The Ethics of Artificial Intelligence for the Sustainable Development Goals*. Springer, 2023.
- Key concepts: decoupling of agency and intelligence, soft ethics, exacerbated/renewed/unprecedented problems, hypersuasion, AI gambit.

**Other concepts from the foundational texts**:

- Antagonistic publics, war of religions, attention economy, vectorial antagonism, cultural battle, earth exhaustion, synthetic intelligence, irregular Anthropocene, technodiversity, effective radicalism, planetary cognitive infrastructures, irreducible entanglement, ambivalent monstrosity, political deficit, cognitive imperialism, triple theoretical emptiness, double strategy.

---

## METHODOLOGICAL APPENDIX

**This essay seeks to**:

1. **Avoid theoretical vacuities**: Do not make exclusive extension of human concepts to AI; do not dissolve everything into empty relational ontologies; do not proliferate identity-based neologisms.

2. **Overcome political deficit**: Do not remain stuck in catastrophic diagnosis; do not appeal to technocratic governance or romantic resistance; propose effective radicalism with concrete practices.

3. **Integrate three frameworks**: Articulate sensory mediation (Hansen), alien reason (Parisi), and decoupled agency (Floridi) as complementary perspectives on the same transformation.

4. **Embrace equivocality**: Do not purify AI as only a threat or promise; do not prematurely resolve tensions; remain open to multiple futures.

5. **Articulate scales**: From molecular (chips) to planetary (energy consumption); from individual (attention) to collective (publics); from material (mining) to procedural (algorithms) to epistemic (knowledge).

6. **Contest territories**: Intervene simultaneously in material, procedural, sensory, organizational, and epistemic strata. Do not limit yourself to one front.

7. **Imagine futures**: Not dystopian or utopian, but desirable, plural, disputable. Show that technodiversity is possible.

8. **Practice effective radicalism**: Neither administrative governance nor pure resistance. Double strategy: assume war (confront) and change terrain (deactivate).

